{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/jiezhang/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori=pd.read_csv(\"fine_data.csv\")\n",
    "data_ori=data_ori.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                       filename  \\\n0            PinkPoemsMadrasEyeConjunctivitisPinkEyePoembyIndiraRenganathan.txt   \n1  WarningPoemsOneDayPehapsILlUnderstandTissuesWarningPoembyivororivorehogg.txt   \n2                            FatherPoemsFatherIMNoCatholicPoembyEboneIngram.txt   \n\n  original_tag  \\\n0         pink   \n1      warning   \n2       father   \n\n                                                                                                                                                    poem  \\\n0  [\"Your territory whence your'I'\", 'Looks into the whole world', 'Blinking for hopeful knowing', 'Now impinged upon', 'Perpetrating culprit acute, ...   \n1  ['They say there is no Santa Claus', 'the bigger kids. Its just your dad', 'I don’t believe their lies of course', 'Although sometimes it makes me...   \n2  [\"Father, i'm no Catholic\", 'but i must Confess:', \"i've been a bad girl.\", \"My mind's Mayor of the Gutter\", \"and my Body's just a tool for him\", ...   \n\n    our_tag  \n0     other  \n1     other  \n2  relation  \n"
     ]
    }
   ],
   "source": [
    "print(data_ori.head(3))\n",
    "#dfF=df[['star_rating','review_body']]\n",
    "#dfprint=dfF.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                                                                                                    poem  \\\n",
      "0  [\"your territory whence your'i'\", 'looks into the whole world', 'blinking for hopeful knowing', 'now impinged upon', 'perpetrating culprit acute, ...   \n",
      "1  ['they say there is no santa claus', 'the bigger kids. its just your dad', 'i don’t believe their lies of course', 'although sometimes it makes me...   \n",
      "2  [\"father, i'm no catholic\", 'but i must confess:', \"i've been a bad girl.\", \"my mind's mayor of the gutter\", \"and my body's just a tool for him\", ...   \n",
      "3  ['butterfly; butterfly fly away,', 'teach me how to be as free as free can be.', 'butterfly; butterfly i see you there,', 'its beautiful the way y...   \n",
      "4  ['i am a young school boy,', 'with a white shirt and black tie,', 'i dream to fly high,', 'like a falcon in the sky,', 'not bothered how, what and...   \n",
      "5  ['oh!', 'the resplendent, red, rotund', 'the early morning sun', 'on the eastern  sea surface', 'or', 'is it a red ball left afloat', 'last evenin...   \n",
      "6  ['you sit inside the car', 'as i drive on this busy road', 'in the city, on some dangerous', 'intersections, and you hold your hair', 'with your l...   \n",
      "7  ['springtime’s first green is gold,', 'her subtlest hue to hold,', 'her morning song’s the flower;', 'but only so one hour.', 'then colors by colo...   \n",
      "8  ['oh, marcia,', 'i want your long blonde beauty', 'to be taught in high school,', 'so kids will learn that god', 'lives like music in the skin', '...   \n",
      "9  ['then run along the riverside', \"upon a time a french king's pride\", 'viewed vast breadth and gentle ripples;', 'glitter, glisten, glow and twink...   \n",
      "\n",
      "    our_tag  \n",
      "0     other  \n",
      "1     other  \n",
      "2  relation  \n",
      "3    travel  \n",
      "4     other  \n",
      "5    travel  \n",
      "6     other  \n",
      "7     other  \n",
      "8   emotion  \n",
      "9    travel  \n",
      "<ipython-input-41-85ca32730ade>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt[\"poem\"]=data_pt[\"poem\"].str.lower()\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_colwidth',150)\n",
    "data_pt=data_ori[[\"poem\",\"our_tag\"]]\n",
    "data_pt[\"poem\"]=data_pt[\"poem\"].str.lower()\n",
    "print(data_pt.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total number poem:  14236\n",
      "['they say there is no santa claus', 'the bigger kids. its just your dad', 'i don’t believe their lies of course', 'although sometimes it makes me sad', 'i haven’t got a dad you see.', 'he died a long, long time ago', 'there’s just my mum my sis and me', 'that’s why i’m certain that i know.', 'there has to be a santa claus.', 'on christmas morning there will be.', 'some presents for each of us', 'in piles beneath the christmas tree.', 'i only six but i know this.', 'that santa works all through the night', 'making sure he does not miss.', 'a chance to bring a child delight.', 'one day i hope to catch the sight', 'of santa claus all dressed in red.', 'but mummy makes me go to bed', 'and she will watch for him instead.', 'she leaves mince pies and ginger wine.', 'then she settles down to wait.', 'my sister goes to bed at nine.', 'mum falls asleep and wakes too late.', 'he’s been and gone, so have the pies', 'while mother slept, kind santa crept', 'into the house and ate the pies.', 'he left our presents while we slept.', 'at least that’s what my mother says.', 'if i should ask why she cries', 'on this the happiest of days.', 'because i miss him she replies.', 'i’m not quite sure i understand', 'the reason for my mummy’s tears', 'santa has gone back to lapland', 'where has lived for years and years.', 'i think my older sister knows', 'a secret that she will not tell', 'she’s not allowed to suppose.', 'because she sometimes cries as well.', 'but i’m a boy and boys don’t cry', 'but when they cry it makes me sad', 'although i really don’t know why.', 'i never really knew my dad.', 'tuesday,01 december 2009', 'http: // blog.myspace.com/poeticpiers']\n"
     ]
    }
   ],
   "source": [
    "total_poem=len(data_pt[\"poem\"])\n",
    "print(\"total number poem: \", total_poem)\n",
    "poem_content=data_pt[\"poem\"].tolist()\n",
    "print(poem_content[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['they say there is no santa claus', 'the bigger kids. its just your dad', 'i don’t believe their lies of course', 'although sometimes it makes me sad', 'i haven’t got a dad you see.', 'he died a long, long time ago', 'there’s just my mum my sis and me', 'that’s why i’m certain that i know.', 'there has to be a santa claus.', 'on christmas morning there will be.', 'some presents for each of us', 'in piles beneath the christmas tree.', 'i only six but i know this.', 'that santa works all through the night', 'making sure he does not miss.', 'a chance to bring a child delight.', 'one day i hope to catch the sight', 'of santa claus all dressed in red.', 'but mummy makes me go to bed', 'and she will watch for him instead.', 'she leaves mince pies and ginger wine.', 'then she settles down to wait.', 'my sister goes to bed at nine.', 'mum falls asleep and wakes too late.', 'he’s been and gone, so have the pies', 'while mother slept, kind santa crept', 'into the house and ate the pies.', 'he left our presents while we slept.', 'at least that’s what my mother says.', 'if i should ask why she cries', 'on this the happiest of days.', 'because i miss him she replies.', 'i’m not quite sure i understand', 'the reason for my mummy’s tears', 'santa has gone back to lapland', 'where has lived for years and years.', 'i think my older sister knows', 'a secret that she will not tell', 'she’s not allowed to suppose.', 'because she sometimes cries as well.', 'but i’m a boy and boys don’t cry', 'but when they cry it makes me sad', 'although i really don’t know why.', 'i never really knew my dad.', 'tuesday,01 december 2009', 'http: // blog.myspace.com/poeticpiers']\ne\n"
     ]
    }
   ],
   "source": [
    "hold=poem_content[1]\n",
    "print(hold)\n",
    "hold=hold[1:len(hold)-1]\n",
    "hold=hold.replace(\"\\\"\",\"\")\n",
    "\n",
    "hold=hold.split(\",\")\n",
    "for i in range(len(hold)):\n",
    "    hold[i]=hold[i].strip(\" \")\n",
    "    hold[i]=hold[i].strip(\"'\")\n",
    "poem_str=\"\"\n",
    "for ele in hold:\n",
    "    poem_str+=\" \"+ele\n",
    "print(poem_str[1:][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "they say there is no santa claus the bigger kids. its just your dad i don’t believe their lies of course although sometimes it makes me sad i haven’t got a dad you see. he died a long long time ago there’s just my mum my sis and me that’s why i’m certain that i know. there has to be a santa claus. on christmas morning there will be. some presents for each of us in piles beneath the christmas tree. i only six but i know this. that santa works all through the night making sure he does not miss. a chance to bring a child delight. one day i hope to catch the sight of santa claus all dressed in red. but mummy makes me go to bed and she will watch for him instead. she leaves mince pies and ginger wine. then she settles down to wait. my sister goes to bed at nine. mum falls asleep and wakes too late. he’s been and gone so have the pies while mother slept kind santa crept into the house and ate the pies. he left our presents while we slept. at least that’s what my mother says. if i should ask why she cries on this the happiest of days. because i miss him she replies. i’m not quite sure i understand the reason for my mummy’s tears santa has gone back to lapland where has lived for years and years. i think my older sister knows a secret that she will not tell she’s not allowed to suppose. because she sometimes cries as well. but i’m a boy and boys don’t cry but when they cry it makes me sad although i really don’t know why. i never really knew my dad. tuesday 01 december 2009 http: // blog.myspace.com/poeticpiers\n"
     ]
    }
   ],
   "source": [
    "def clean(gg):\n",
    "    gg=gg[1:len(gg)-1]\n",
    "    gg=gg.replace(\"\\\"\",\"\")\n",
    "\n",
    "    gg=gg.split(\",\")\n",
    "    for i in range(len(gg)):\n",
    "        gg[i]=gg[i].strip(\" \")\n",
    "        gg[i]=gg[i].strip(\"'\")\n",
    "    poem_str=\"\"\n",
    "    for ele in gg:\n",
    "        poem_str+=\" \"+ele\n",
    "    return poem_str[1:]\n",
    "print(clean(poem_content[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                                                                                                    poem  \\\n",
      "0  your territory whence your'i looks into the whole world blinking for hopeful knowing now impinged upon perpetrating culprit acute viral trenching ...   \n",
      "1  they say there is no santa claus the bigger kids. its just your dad i don’t believe their lies of course although sometimes it makes me sad i have...   \n",
      "2  father i'm no catholic but i must confess: i've been a bad girl. my mind's mayor of the gutter and my body's just a tool for him (whoever 'he' is....   \n",
      "3  butterfly; butterfly fly away  teach me how to be as free as free can be. butterfly; butterfly i see you there  its beautiful the way your wings c...   \n",
      "4  i am a young school boy  with a white shirt and black tie  i dream to fly high  like a falcon in the sky  not bothered how what and why? we are a ...   \n",
      "5  oh! the resplendent red rotund the early morning sun on the eastern  sea surface or is it a red ball left afloat last evening after play by urchin...   \n",
      "6  you sit inside the car as i drive on this busy road in the city on some dangerous intersections and you hold your hair with your left hand leaning...   \n",
      "7  springtime’s first green is gold  her subtlest hue to hold  her morning song’s the flower; but only so one hour. then colors by colors surrender  ...   \n",
      "8  oh marcia  i want your long blonde beauty to be taught in high school  so kids will learn that god lives like music in the skin and sounds like a ...   \n",
      "9  then run along the riverside upon a time a french king's pride viewed vast breadth and gentle ripples; glitter glisten glow and twinkle. inhale th...   \n",
      "\n",
      "    our_tag  \n",
      "0     other  \n",
      "1     other  \n",
      "2  relation  \n",
      "3    travel  \n",
      "4     other  \n",
      "5    travel  \n",
      "6     other  \n",
      "7     other  \n",
      "8   emotion  \n",
      "9    travel  \n",
      "<ipython-input-45-d5c000c846f5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt[\"poem\"]=poem_content\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(poem_content)):\n",
    "    poem_content[i]=clean(poem_content[i])\n",
    "data_pt[\"poem\"]=poem_content\n",
    "print(data_pt.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-46-755adb6dea8b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt['poem'] = data_pt['poem'].replace('http\\S*','',regex=True)\n",
      "<ipython-input-46-755adb6dea8b>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt['poem'] = data_pt['poem'].replace('<[^>]*>','',regex=True)\n",
      "<ipython-input-46-755adb6dea8b>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt['poem'] = data_pt['poem'].replace('[^\\w\\s\\']+','',regex=True)\n",
      "<ipython-input-46-755adb6dea8b>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt['poem'] = data_pt['poem'].replace('\\d*','',regex=True)\n",
      "0    your territory whence your'i looks into the whole world blinking for hopeful knowing now impinged upon perpetrating culprit acute viral trenching ...\n",
      "1    they say there is no santa claus the bigger kids its just your dad i dont believe their lies of course although sometimes it makes me sad i havent...\n",
      "2    father i'm no catholic but i must confess i've been a bad girl my mind's mayor of the gutter and my body's just a tool for him whoever 'he' is fan...\n",
      "3    butterfly butterfly fly away teach me how to be as free as free can be butterfly butterfly i see you there its beautiful the way your wings caress...\n",
      "4    i am a young school boy with a white shirt and black tie i dream to fly high like a falcon in the sky not bothered how what and why we are a gang ...\n",
      "5    oh the resplendent red rotund the early morning sun on the eastern sea surface or is it a red ball left afloat last evening after play by urchins ...\n",
      "6    you sit inside the car as i drive on this busy road in the city on some dangerous intersections and you hold your hair with your left hand leaning...\n",
      "7    springtimes first green is gold her subtlest hue to hold her morning songs the flower but only so one hour then colors by colors surrender so eden...\n",
      "8    oh marcia i want your long blonde beauty to be taught in high school so kids will learn that god lives like music in the skin and sounds like a su...\n",
      "9    then run along the riverside upon a time a french king's pride viewed vast breadth and gentle ripples glitter glisten glow and twinkle inhale the ...\n",
      "Name: poem, dtype: object\n",
      "<ipython-input-46-755adb6dea8b>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt['poem'] = data_pt['poem'].replace(' {2,}',' ',regex=True)\n",
      "<ipython-input-46-755adb6dea8b>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt['poem'] = data_pt['poem'].replace('^\\s*','',regex=True)\n"
     ]
    }
   ],
   "source": [
    "# remove URL\n",
    "data_pt['poem'] = data_pt['poem'].replace('http\\S*','',regex=True)\n",
    "data_pt['poem'] = data_pt['poem'].replace('<[^>]*>','',regex=True)\n",
    "#remove non-alphabite\n",
    "data_pt['poem'] = data_pt['poem'].replace('[^\\w\\s\\']+','',regex=True)\n",
    "data_pt['poem'] = data_pt['poem'].replace('\\d*','',regex=True)\n",
    "#remove extra space\n",
    "data_pt['poem'] = data_pt['poem'].replace(' {2,}',' ',regex=True)\n",
    "data_pt['poem'] = data_pt['poem'].replace('^\\s*','',regex=True)\n",
    "\n",
    "print(data_pt['poem'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-47-1b83f935a3a7>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['poem'] = s['poem'].replace('\\'ll',' will',regex=True)\n",
      "<ipython-input-47-1b83f935a3a7>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['poem'] = s['poem'].replace('\\'ve',' have',regex=True)\n",
      "<ipython-input-47-1b83f935a3a7>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['poem'] = s['poem'].replace('\\'s',' is',regex=True)\n",
      "<ipython-input-47-1b83f935a3a7>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['poem'] = s['poem'].replace('\\'m',' am',regex=True)\n",
      "<ipython-input-47-1b83f935a3a7>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['poem'] = s['poem'].replace('\\'t',' not',regex=True)\n",
      "<ipython-input-47-1b83f935a3a7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['poem'] = s['poem'].replace('\\'re',' are',regex=True)\n",
      "                                                                                                                                                    poem  \\\n",
      "0  your territory whence your'i looks into the whole world blinking for hopeful knowing now impinged upon perpetrating culprit acute viral trenching ...   \n",
      "1  they say there is no santa claus the bigger kids its just your dad i dont believe their lies of course although sometimes it makes me sad i havent...   \n",
      "2  father i am no catholic but i must confess i have been a bad girl my mind is mayor of the gutter and my body is just a tool for him whoever 'he' i...   \n",
      "\n",
      "    our_tag  \n",
      "0     other  \n",
      "1     other  \n",
      "2  relation  \n",
      "<ipython-input-47-1b83f935a3a7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['poem'] = s['poem'].replace('\\'d',' would',regex=True)\n"
     ]
    }
   ],
   "source": [
    "def contractionfunction(s):\n",
    "    s['poem'] = s['poem'].replace('\\'ll',' will',regex=True)\n",
    "    s['poem'] = s['poem'].replace('\\'ve',' have',regex=True)\n",
    "    s['poem'] = s['poem'].replace('\\'s',' is',regex=True)\n",
    "    s['poem'] = s['poem'].replace('\\'m',' am',regex=True)\n",
    "    s['poem'] = s['poem'].replace('\\'t',' not',regex=True)\n",
    "    s['poem'] = s['poem'].replace('\\'re',' are',regex=True)\n",
    "    s['poem'] = s['poem'].replace('\\'d',' would',regex=True)\n",
    "    return s\n",
    "data_pt_clean=contractionfunction(data_pt)\n",
    "print(data_pt_clean.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jiezhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "                                                                                                                                                    poem  \\\n",
      "0  [territory, whence, your'i, looks, whole, world, blinking, hopeful, knowing, impinged, upon, perpetrating, culprit, acute, viral, trenching, viole...   \n",
      "1  [say, santa, claus, bigger, kids, dad, dont, believe, lies, course, although, sometimes, makes, sad, havent, got, dad, see, died, long, long, time...   \n",
      "2  [father, catholic, must, confess, bad, girl, mind, mayor, gutter, body, tool, whoever, 'he', fantasies, harsh, reality, maybe, little, fastfurious...   \n",
      "\n",
      "    our_tag  \n",
      "0     other  \n",
      "1     other  \n",
      "2  relation  \n",
      "<ipython-input-48-d243c7b5cee4>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt_clean['poem']=data_pt_clean['poem'].apply(lambda x: [item for item in str(x).split() if item not in stop])\n"
     ]
    }
   ],
   "source": [
    "#remove stop word\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "#print(stop)\n",
    "data_pt_clean['poem']=data_pt_clean['poem'].apply(lambda x: [item for item in str(x).split() if item not in stop])\n",
    "\n",
    "print(data_pt_clean.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sample review after data clean and preprogress\n",
      "                                                                                                                                                    poem  \\\n",
      "0  [territory, whence, your'i, look, whole, world, blinking, hopeful, knowing, impinged, upon, perpetrating, culprit, acute, viral, trenching, violen...   \n",
      "1  [say, santa, claus, bigger, kid, dad, dont, believe, lie, course, although, sometimes, make, sad, havent, got, dad, see, died, long, long, time, a...   \n",
      "2  [father, catholic, must, confess, bad, girl, mind, mayor, gutter, body, tool, whoever, 'he', fantasy, harsh, reality, maybe, little, fastfurious, ...   \n",
      "\n",
      "    our_tag  \n",
      "0     other  \n",
      "1     other  \n",
      "2  relation  \n",
      "<ipython-input-49-c2df2c897195>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt_clean['poem']=data_pt_clean['poem'].apply(lemmatize_text)\n"
     ]
    }
   ],
   "source": [
    "#perform lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    return [lemmatizer.lemmatize(w,'n') for w in text]\n",
    "\n",
    "\n",
    "data_pt_clean['poem']=data_pt_clean['poem'].apply(lemmatize_text)\n",
    "\n",
    "print(\"sample review after data clean and preprogress\")\n",
    "print(data_pt_clean.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "average length is:  97.71459679685304\n",
      "<ipython-input-50-07d3e7e8108d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt_clean[\"our_tag\"]=tags\n",
      "<ipython-input-50-07d3e7e8108d>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_pt_clean['poem']=data_pt_clean['poem'].apply(', '.join)\n"
     ]
    }
   ],
   "source": [
    "tag_dic={\"emotion\":0,\"relation\":1,\"location\":2,\"other\":3,\"art\":4,\"romance\":5,\"travel\":6}\n",
    "tags=data_pt_clean[\"our_tag\"].tolist()\n",
    "for i in range(len(tags)):\n",
    "    tags[i]=tag_dic[tags[i]]\n",
    "data_pt_clean[\"our_tag\"]=tags\n",
    "\n",
    "#for word2vec use\n",
    "data_word2vec=data_pt_clean.copy(deep=True)\n",
    "\n",
    "length=0\n",
    "number=0\n",
    "for poem in data_word2vec[\"poem\"]:\n",
    "    length+=len(poem)\n",
    "    number+=1\n",
    "print(\"average length is: \",length/number)\n",
    "\n",
    "data_pt_clean['poem']=data_pt_clean['poem'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14236, 10168)\n"
     ]
    }
   ],
   "source": [
    "#Get TF-IDF\n",
    "\n",
    "\n",
    "from nltk.text import TextCollection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    " #corpus = TextCollection(dfTrain['review_body'])\n",
    "\n",
    "v = TfidfVectorizer(min_df=10)\n",
    "\n",
    "\n",
    "x = v.fit_transform(data_pt_clean[\"poem\"])\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "717.3557881427367\n",
      "Train accuracy:  0.955076923076923\n",
      "Test accuracy:  0.529126213592233\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "total=0\n",
    "for rows in data_pt_clean['poem']:\n",
    "    total=total+len(str(rows))\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def dataOutput(model,corpus,features):\n",
    "  predict=model.predict(features)\n",
    "  TPData=predict+corpus['out_tag']\n",
    "  TP=TPData.value_counts()[2]\n",
    "  \n",
    "  precision=TP/Counter(predict)[1]\n",
    "  recall=TP/corpus[\"our_tag\"].value_counts()[1]\n",
    "  F1=2*precision*recall/(precision+recall)\n",
    "  return precision,recall,F1\n",
    "\n",
    "print(total/14236)\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "data_Train=data_pt_clean[0:13000]\n",
    "data_Test=data_pt_clean[13000:]\n",
    "\n",
    "\n",
    "\n",
    "xTrain=x[0:13000]\n",
    "xTest=x[13000:]\n",
    "\n",
    "\n",
    "\n",
    "clf=Perceptron(fit_intercept=False, shuffle=False)\n",
    "clf.fit(xTrain,data_Train['our_tag'])\n",
    "\n",
    "\n",
    "Taccuracy=clf.score(xTrain,data_Train['our_tag'])\n",
    "print(\"Train accuracy: \", Taccuracy)\n",
    "\n",
    "accuracy=clf.score(xTest,data_Test['our_tag'])\n",
    "print(\"Test accuracy: \", accuracy)\n",
    "#Pprecision,Precall,PF1=dataOutput(clf,data_Test,xTest)\n",
    "\n",
    "\n",
    "#Tprecision,Trecall,TF1=dataOutput(clf,data_Train,xTrain)\n",
    "\n",
    "#print(\"In Perceptron, For Train data. Accuracy: \",Taccuracy,\" Precision: \",Tprecision,\" Recall: \",Trecall,\" f1: \",TF1)\n",
    "#print(\"In Perceptron, For Test data. Accuracy: \",accuracy,\" Precision: \",Pprecision,\" Recall: \",Precall,\" f1: \",PF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM Train accuracy:  0.7044615384615385\nSVM Test accuracy:  0.5938511326860841\nTrain F1:\nTrain f1 score micro 0.7044615384615385\nTrain f1 score macro 0.6110773198656014\nTrain f1 score weighted 0.6935462916567476\nTest F1:\nTest f1 score micro 0.5938511326860841\nTest f1 score macro 0.5221748496239877\nTest f1 score weighted 0.5810475027557427\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "clfSVM=svm.LinearSVC(loss='squared_hinge',dual=False,multi_class=\"ovr\",C=0.05,tol=0.00001)\n",
    "clfSVM.fit(xTrain,data_Train['our_tag'])\n",
    "acc=clfSVM.score(xTest,data_Test['our_tag'])\n",
    "Tacc=clfSVM.score(xTrain,data_Train['our_tag'])\n",
    "print(\"SVM Train accuracy: \", Tacc)\n",
    "\n",
    "print(\"SVM Test accuracy: \", acc)\n",
    "\n",
    "test_predict=clfSVM.predict(xTest)\n",
    "train_predict=clfSVM.predict(xTrain)\n",
    "\n",
    "print(\"Train F1:\")\n",
    "print(\"Train f1 score micro\",f1_score(data_Train['our_tag'],train_predict,average='micro'))\n",
    "print(\"Train f1 score macro\",f1_score(data_Train ['our_tag'],train_predict,average='macro'))\n",
    "print(\"Train f1 score weighted\",f1_score(data_Train['our_tag'],train_predict,average='weighted'))\n",
    "print(\"Test F1:\")\n",
    "print(\"Test f1 score micro\",f1_score(data_Test['our_tag'],test_predict,average='micro'))\n",
    "print(\"Test f1 score macro\",f1_score(data_Test['our_tag'],test_predict,average='macro'))\n",
    "print(\"Test f1 score weighted\",f1_score(data_Test['our_tag'],test_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "logistic Train accuracy:  0.6942307692307692\nlogistic Test accuracy:  0.5849514563106796\nTest f1 score micro 0.5849514563106796\nTest f1 score macro 0.5000890592773725\nTest f1 score weighted 0.5713923885339091\n"
     ]
    }
   ],
   "source": [
    "#logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(solver='liblinear',fit_intercept=False,C=0.5,tol=0.0001)\n",
    "model.fit(xTrain,data_Train['our_tag'])\n",
    "\n",
    "acc_train=model.score(xTrain,data_Train['our_tag'])\n",
    "\n",
    "print(\"logistic Train accuracy: \", acc_train)\n",
    "\n",
    "print(\"logistic Test accuracy: \",model.score(xTest,data_Test['our_tag']))\n",
    "\n",
    "\n",
    "test_predict=model.predict(xTest)\n",
    "\n",
    "print(\"Test f1 score micro\",f1_score(data_Test['our_tag'],test_predict,average='micro'))\n",
    "print(\"Test f1 score macro\",f1_score(data_Test['our_tag'],test_predict,average='macro'))\n",
    "\n",
    "print(\"Test f1 score weighted\",f1_score(data_Test['our_tag'],test_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive bayes Train accuracy:  0.7860769230769231\n",
      "Naive bayes Test accuracy:  0.4749190938511327\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    }
   ],
   "source": [
    "#Naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clfNB=MultinomialNB(alpha=0)\n",
    "clfNB.fit(xTrain,data_Train['our_tag'])\n",
    "acc=clfNB.score(xTest,data_Test['our_tag'])\n",
    "\n",
    "accTrain=clfNB.score(xTrain,data_Train['our_tag'])\n",
    "\n",
    "print(\"Naive bayes Train accuracy: \",accTrain)\n",
    "\n",
    "print(\"Naive bayes Test accuracy: \",acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                                                                                                    poem  \\\n0  [territory, whence, your'i, look, whole, world, blinking, hopeful, knowing, impinged, upon, perpetrating, culprit, acute, viral, trenching, violen...   \n1  [say, santa, claus, bigger, kid, dad, dont, believe, lie, course, although, sometimes, make, sad, havent, got, dad, see, died, long, long, time, a...   \n2  [father, catholic, must, confess, bad, girl, mind, mayor, gutter, body, tool, whoever, 'he', fantasy, harsh, reality, maybe, little, fastfurious, ...   \n3  [butterfly, butterfly, fly, away, teach, free, free, butterfly, butterfly, see, beautiful, way, wing, caress, air, butterfly, butterfly, go, high,...   \n4  [young, school, boy, white, shirt, black, tie, dream, fly, high, like, falcon, sky, bothered, gang, five, friend, try, read, play, young, school, ...   \n\n   our_tag  \n0        3  \n1        3  \n2        1  \n3        6  \n4        3  \n"
     ]
    }
   ],
   "source": [
    "#Word2Vec\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "\n",
    "print(data_word2vec.head(5))\n",
    "\n",
    "sentences = data_word2vec['poem']\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences=sentences,vector_size=300,window=5,min_count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "poem feature extration finished\n"
     ]
    }
   ],
   "source": [
    "weights=[]\n",
    "\n",
    "for rows in data_word2vec['poem']:\n",
    "  w=np.array([0]*300)\n",
    "  misC=0\n",
    "  for ele in rows:\n",
    "    try:\n",
    "      wordV=model.wv[ele]\n",
    "    except:\n",
    "      misC+=1\n",
    "      wordV=np.array([0]*300)\n",
    "    w=np.sum([w,wordV],axis=0).tolist()\n",
    "  if len(rows)!=0 and len(rows)!=misC:\n",
    "    weights.append(np.array([x/(len(rows)-misC) for x in w]))\n",
    "  else:\n",
    "    weights.append(np.array(w))\n",
    "\n",
    "print(\"poem feature extration finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start Test\nmy own W2v for perceptor accuracy is :  0.28883495145631066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#word2Vect Perceptron\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "#weightsD=pd.DataFrame(weights)\n",
    "\n",
    "\n",
    "weightsTrain=weights[0:13000]\n",
    "weightsTest=weights[13000:]\n",
    "\n",
    "data_word2vec_train=data_word2vec[0:13000]\n",
    "data_word2vec_test=data_word2vec[13000:]\n",
    "\n",
    "\n",
    "# own model\n",
    "clf=Perceptron(fit_intercept=False, shuffle=False)\n",
    "clf.fit(weightsTrain,data_word2vec_train['our_tag'])\n",
    "\n",
    "print(\"Start Test\")\n",
    "accuracy=clf.score(weightsTest,data_word2vec_test['our_tag'])\n",
    "print(\"my own W2v for perceptor accuracy is : \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word2Vec logistic Train accuracy:  0.4976923076923077\nWord2Vec logistic Test accuracy:  0.4692556634304207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#word2vec logistic\n",
    "\n",
    "Logmodel = LogisticRegression(solver='liblinear',fit_intercept=False,C=1,tol=0.000001)\n",
    "Logmodel.fit(weightsTrain,data_word2vec_train['our_tag'])\n",
    "\n",
    "acc_train=Logmodel.score(weightsTrain,data_word2vec_train['our_tag'])\n",
    "\n",
    "print(\"Word2Vec logistic Train accuracy: \", acc_train)\n",
    "\n",
    "print(\"Word2Vec logistic Test accuracy: \",Logmodel.score(weightsTest,data_word2vec_test['our_tag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word2vec SVM Train accuracy:  0.48938461538461536\nWord2Vec SVM Test accuracy:  0.4563106796116505\n"
     ]
    }
   ],
   "source": [
    "#Word2vec SVM\n",
    "\n",
    "clfSVM=svm.LinearSVC(loss='squared_hinge',dual=False,multi_class=\"ovr\",C=0.05,tol=0.00001)\n",
    "\n",
    "clfSVM.fit(weightsTrain,data_word2vec_train['our_tag'])\n",
    "\n",
    "acc=clfSVM.score(weightsTest,data_word2vec_test['our_tag'])\n",
    "Trainacc=clfSVM.score(weightsTrain,data_word2vec_train['our_tag'])\n",
    "\n",
    "print(\"Word2vec SVM Train accuracy: \", Trainacc)\n",
    "\n",
    "print(\"Word2Vec SVM Test accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word2Vec Naive bayes Train accuracy:  0.3533846153846154\nWordVec Naive bayes Test accuracy:  0.3220064724919094\n"
     ]
    }
   ],
   "source": [
    "#word2Vec Navive bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clfNB=GaussianNB()\n",
    "clfNB.fit(weightsTrain,data_word2vec_train['our_tag'])\n",
    "acc=clfNB.score(weightsTest,data_word2vec_test['our_tag'])\n",
    "\n",
    "accTrain=clfNB.score(weightsTrain,data_word2vec_train['our_tag'])\n",
    "\n",
    "print(\"Word2Vec Naive bayes Train accuracy: \",accTrain)\n",
    "\n",
    "print(\"WordVec Naive bayes Test accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data conbine Finished \n"
     ]
    }
   ],
   "source": [
    "#conbine data\n",
    "hold=[]\n",
    "for ele in data_word2vec_train['our_tag']:\n",
    "  h1=np.array([ele])\n",
    "  h2=torch.from_numpy(h1).float()\n",
    "  hold.append(h2)\n",
    "comb=[]\n",
    "for i in range(len(hold)):\n",
    "  comb.append([weightsTrain[i],hold[i]])\n",
    "\n",
    "hold=[]\n",
    "for ele in data_word2vec_test['our_tag']:\n",
    "  h1=np.array([ele])\n",
    "  h2=torch.from_numpy(h1).float()\n",
    "  hold.append(h2)\n",
    "combTest=[]\n",
    "for j in range(len(hold)):\n",
    "  combTest.append([weightsTest[j],hold[j]])\n",
    "\n",
    "#print(comb[0])\n",
    "print(\"data conbine Finished \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # number of hidden nodes in each layer (512)\n",
    "        hidden_1 = 100\n",
    "        hidden_2 = 20\n",
    "        # linear layer (784 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(1*300, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.fc3 = nn.Linear(hidden_2, 7)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 1*300)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        #x = self.dropout(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        #x = self.dropout(x)\n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word2Vec(vocab=5203, vector_size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "modelFNN = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train acc:  0.4666923076923077\n",
      "Epoch: 1 \tTraining Loss: 508.029433 \tValidation Loss: 511.575094\n",
      "Validation loss decreased (inf --> 511.575094).  Saving model ...\n",
      "Train acc:  0.4726923076923077\n",
      "Epoch: 2 \tTraining Loss: 506.237205 \tValidation Loss: 516.206159\n",
      "Train acc:  0.47284615384615386\n",
      "Epoch: 3 \tTraining Loss: 506.343117 \tValidation Loss: 507.046614\n",
      "Validation loss decreased (511.575094 --> 507.046614).  Saving model ...\n",
      "Train acc:  0.47923076923076924\n",
      "Epoch: 4 \tTraining Loss: 504.310473 \tValidation Loss: 505.999468\n",
      "Validation loss decreased (507.046614 --> 505.999468).  Saving model ...\n",
      "Train acc:  0.48384615384615387\n",
      "Epoch: 5 \tTraining Loss: 503.164083 \tValidation Loss: 507.209195\n",
      "Train acc:  0.48746153846153845\n",
      "Epoch: 6 \tTraining Loss: 501.799010 \tValidation Loss: 507.824778\n",
      "Train acc:  0.49053846153846153\n",
      "Epoch: 7 \tTraining Loss: 501.297735 \tValidation Loss: 506.344086\n",
      "Train acc:  0.49423076923076925\n",
      "Epoch: 8 \tTraining Loss: 499.738243 \tValidation Loss: 502.932890\n",
      "Validation loss decreased (505.999468 --> 502.932890).  Saving model ...\n",
      "Train acc:  0.4929230769230769\n",
      "Epoch: 9 \tTraining Loss: 500.589528 \tValidation Loss: 502.709411\n",
      "Validation loss decreased (502.932890 --> 502.709411).  Saving model ...\n",
      "Train acc:  0.4960769230769231\n",
      "Epoch: 10 \tTraining Loss: 499.597108 \tValidation Loss: 507.740033\n",
      "Train acc:  0.49976923076923074\n",
      "Epoch: 11 \tTraining Loss: 498.590587 \tValidation Loss: 505.444371\n",
      "Train acc:  0.5015384615384615\n",
      "Epoch: 12 \tTraining Loss: 498.012957 \tValidation Loss: 504.383879\n",
      "Train acc:  0.5036153846153846\n",
      "Epoch: 13 \tTraining Loss: 497.335699 \tValidation Loss: 506.185874\n",
      "Train acc:  0.5036923076923077\n",
      "Epoch: 14 \tTraining Loss: 497.501378 \tValidation Loss: 503.547075\n",
      "Train acc:  0.5070769230769231\n",
      "Epoch: 15 \tTraining Loss: 496.260418 \tValidation Loss: 507.262000\n",
      "Train acc:  0.504\n",
      "Epoch: 16 \tTraining Loss: 497.441081 \tValidation Loss: 499.253724\n",
      "Validation loss decreased (502.709411 --> 499.253724).  Saving model ...\n",
      "Train acc:  0.5088461538461538\n",
      "Epoch: 17 \tTraining Loss: 495.846767 \tValidation Loss: 498.941590\n",
      "Validation loss decreased (499.253724 --> 498.941590).  Saving model ...\n",
      "Train acc:  0.5076153846153846\n",
      "Epoch: 18 \tTraining Loss: 496.226731 \tValidation Loss: 503.460017\n",
      "Train acc:  0.5111538461538462\n",
      "Epoch: 19 \tTraining Loss: 495.173202 \tValidation Loss: 495.415604\n",
      "Validation loss decreased (498.941590 --> 495.415604).  Saving model ...\n",
      "Train acc:  0.5112307692307693\n",
      "Epoch: 20 \tTraining Loss: 494.770050 \tValidation Loss: 496.241577\n",
      "my own w2v for FNN 300 size vector accuracy is:  0.4401294498381877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.Adam(modelFNN.parameters(), lr=0.001)\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    num_correct=0.0\n",
    "\n",
    "    train_cor=0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    modelFNN.train() # prep model for training\n",
    "    for data, target in comb:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = modelFNN(torch.from_numpy(data).float())\n",
    "        output=F.softmax(output,dim=1)\n",
    "        # calculate the loss\n",
    "\n",
    "        loss = criterion(output, target.type(torch.LongTensor))\n",
    "        #print(output,target)\n",
    "        #num_correct += torch.eq(output, target).sum().float().item()\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "       \n",
    "        train_loss += loss.item()*(torch.from_numpy(data).float()).size(0)\n",
    "\n",
    "        predict=torch.max(output.data,dim=1)\n",
    "        if torch.eq(predict.indices,target):\n",
    "          train_cor+=1\n",
    "    print(\"Train acc: \",train_cor/len(weightsTrain))\n",
    "\n",
    "    \n",
    "    modelFNN.eval() # prep model for evaluation\n",
    "    for data, target in comb[:1000]:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = modelFNN(torch.from_numpy(data).float())\n",
    "        # calculate the loss\n",
    "        output=F.softmax(output,dim=1)\n",
    "        loss = criterion(output, target.type(torch.LongTensor))\n",
    "        # update running validation loss\n",
    "        #print(loss.item())\n",
    "        #print((torch.from_numpy(data).float()).size(0))\n",
    "\n",
    "        valid_loss += loss.item()*(torch.from_numpy(data).float()).size(0)\n",
    "        predict=torch.max(output.data,dim=1)\n",
    "        if torch.eq(predict.indices,target):\n",
    "          num_correct+=1\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    #print(train_loss)\n",
    "    #print(valid_loss)\n",
    "    train_loss = train_loss/len(weightsTrain)\n",
    "    valid_loss = valid_loss/1000\n",
    "    #print(\"my own W2v for FNN 300 size vector accuracy is : \",num_correct/len(weightTest))\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(modelFNN.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "num_correct=0\n",
    "for data, target in combTest:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = modelFNN(torch.from_numpy(data).float())\n",
    "        # calculate the loss\n",
    "        output=F.softmax(output,dim=1)\n",
    "        loss = criterion(output, target.type(torch.LongTensor))\n",
    "        # update running validation loss\n",
    "        #print(loss.item())\n",
    "        #print((torch.from_numpy(data).float()).size(0))\n",
    "\n",
    "        valid_loss += loss.item()*(torch.from_numpy(data).float()).size(0)\n",
    "        predict=torch.max(output.data,dim=1)\n",
    "        if torch.eq(predict.indices,target):\n",
    "          num_correct+=1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"my own w2v for FNN 300 size vector accuracy is: \",num_correct/len(weightsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}